# LLM playground üõù
This project will create the basis of a future project I plan to begin. I am prioritizing the main piece of software that is will be developing an LLM which needs preperation. Then later a full scale app will be using this llm model.

# TODOS (asses inference speed & plasticity)
1. ‚úÖ System prompt several models see if embodies the 2001 character HAL-9000
2. ‚ùå Instruction tune each new model in inference time and observe inference speed and model plasticity/adabtability.
3. ‚úÖ With my gut feelings, select few winner models to proceed with "HAL-9000" likeness.
4. Proceed with winner model with further Fine tuning based on custom dataset.
5. Implement RAG? Agent Calling? ReAct?

## DONE

what is completed so far...
* installed langchain_community
* installed several 7B models with Ollama
* installed crewai
* installed openai
* installed langchain-google-genai
* installed google-serp-api
* played with we research langchain tools and Ollama
* created Ollama testing code to evaluate inference speed for several models.
* System Prompts used, evaluate inference speed.
* Evaluated responses to prompts based on personal preference / gut feeling.
* To not lose time, evaluated mean response times and mean length of generated responses.
* Will proceed with **llama2:7b:chat**, **llava2:13b**, **neural-chat:7b**, **gemma:2b:instruct**

## Refereces

* <https://www.youtube.com/watch?v=kJvXT25LkwA&ab_channel=MayaAkim>
* <https://www.youtube.com/watch?v=xa8pTD16SnM&t=171s&ab_channel=Decoder>
* <https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety>
* <https://python.langchain.com/docs/integrations/tools>
* <https://ollama.com/library>
* <https://docs.google.com/spreadsheets/d/1b0jZwkdgCe0-k62X7YRwKkKCK7Jh9ckbVuplFPsq8CA/edit?usp=sharing>
