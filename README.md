# LLM playground ğŸ›

# TODOS (asses inference speed & plasticity)
1. Proceed with winner model with further Fine tuning based on custom dataset.
2. Implement RAG? Agent Calling? ReAct?

## DONE
* Will proceed with **llama2:7b:chat**, **llava2:13b**, **neural-chat:7b**, **gemma:2b:instruct**

## Refereces

* 
